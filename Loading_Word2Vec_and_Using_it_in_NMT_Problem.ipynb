{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Loading_Word2Vec and Using it in NMT Problem.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Steps to Download and load Word2vec\n",
        "1. Download word2vec from https://code.google.com/archive/p/word2vec/\n",
        "2. Unzip it and then upload it to the google drive"
      ],
      "metadata": {
        "id": "GpKYbwIxF3LC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import KeyedVectors\n",
        "# Load vectors directly from the file\n",
        "model = KeyedVectors.load_word2vec_format('/content/drive/MyDrive/GoogleNews-vectors-negative300.bin', binary=True)"
      ],
      "metadata": {
        "id": "MIHqGKlaKXTl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(model)"
      ],
      "metadata": {
        "id": "lfDjzaDEKXVa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30aa37ae-ccb5-49db-d136-e12abfc3e14d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "gensim.models.keyedvectors.Word2VecKeyedVectors"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model['the']"
      ],
      "metadata": {
        "id": "F4PEFEY8KXYA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b36e3692-7ceb-4f80-c2d9-a777963729b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.08007812,  0.10498047,  0.04980469,  0.0534668 , -0.06738281,\n",
              "       -0.12060547,  0.03515625, -0.11865234,  0.04394531,  0.03015137,\n",
              "       -0.05688477, -0.07617188,  0.01287842,  0.04980469, -0.08496094,\n",
              "       -0.06347656,  0.00628662, -0.04321289,  0.02026367,  0.01330566,\n",
              "       -0.01953125,  0.09277344, -0.171875  , -0.00131989,  0.06542969,\n",
              "        0.05834961, -0.08251953,  0.0859375 , -0.00318909,  0.05859375,\n",
              "       -0.03491211, -0.0123291 , -0.0480957 , -0.00302124,  0.05639648,\n",
              "        0.01495361, -0.07226562, -0.05224609,  0.09667969,  0.04296875,\n",
              "       -0.03540039, -0.07324219,  0.03271484, -0.06176758,  0.00787354,\n",
              "        0.0035553 , -0.00878906,  0.0390625 ,  0.03833008,  0.04443359,\n",
              "        0.06982422,  0.01263428, -0.00445557, -0.03320312, -0.04272461,\n",
              "        0.09765625, -0.02160645, -0.0378418 ,  0.01190186, -0.01391602,\n",
              "       -0.11328125,  0.09326172, -0.03930664, -0.11621094,  0.02331543,\n",
              "       -0.01599121,  0.02636719,  0.10742188, -0.00466919,  0.09619141,\n",
              "        0.0279541 , -0.05395508,  0.08544922, -0.03686523, -0.02026367,\n",
              "       -0.08544922,  0.125     ,  0.14453125,  0.0267334 ,  0.15039062,\n",
              "        0.05273438, -0.18652344,  0.08154297, -0.01062012, -0.03735352,\n",
              "       -0.07324219, -0.07519531,  0.03613281, -0.13183594,  0.00616455,\n",
              "        0.05078125,  0.04516602,  0.0100708 , -0.15039062, -0.06005859,\n",
              "        0.05761719, -0.00692749,  0.01586914, -0.0213623 ,  0.10351562,\n",
              "       -0.00029182, -0.046875  , -0.01635742, -0.07861328, -0.06933594,\n",
              "        0.01635742, -0.03149414, -0.01373291, -0.03662109, -0.08886719,\n",
              "       -0.0480957 , -0.01318359, -0.07177734,  0.00588989, -0.04614258,\n",
              "        0.03979492,  0.10058594, -0.04931641,  0.07568359,  0.03881836,\n",
              "       -0.16699219, -0.09619141, -0.10107422,  0.02905273, -0.05786133,\n",
              "       -0.01928711, -0.04296875, -0.08398438, -0.01989746,  0.05151367,\n",
              "        0.00848389, -0.03613281, -0.14941406, -0.01855469, -0.03637695,\n",
              "       -0.07666016, -0.03955078, -0.06152344, -0.02001953,  0.04150391,\n",
              "        0.03686523, -0.07226562,  0.00592041, -0.06298828,  0.00738525,\n",
              "       -0.01586914,  0.01611328, -0.01452637,  0.00772095,  0.10107422,\n",
              "       -0.00558472,  0.01428223, -0.07617188,  0.05639648, -0.01293945,\n",
              "        0.03063965, -0.02490234, -0.09863281,  0.0324707 , -0.02807617,\n",
              "       -0.08105469,  0.02062988,  0.01611328, -0.04199219, -0.03491211,\n",
              "       -0.03759766,  0.05493164,  0.01373291,  0.02685547, -0.05859375,\n",
              "       -0.07177734, -0.12011719, -0.02282715, -0.1640625 , -0.00361633,\n",
              "       -0.05981445,  0.07080078, -0.07714844,  0.05175781, -0.04296875,\n",
              "       -0.04833984,  0.0300293 , -0.06591797, -0.03173828, -0.04882812,\n",
              "       -0.03491211,  0.05883789, -0.01464844,  0.18066406,  0.05688477,\n",
              "        0.05249023,  0.05786133,  0.11669922,  0.05200195, -0.0534668 ,\n",
              "        0.01867676, -0.015625  ,  0.00576782, -0.07324219, -0.11621094,\n",
              "        0.04052734,  0.0625    , -0.04321289,  0.01055908,  0.02172852,\n",
              "        0.04248047,  0.03271484,  0.04418945,  0.05761719,  0.02612305,\n",
              "       -0.01831055, -0.02697754, -0.00674438,  0.00509644, -0.11621094,\n",
              "        0.00364685,  0.05761719, -0.05957031, -0.08837891,  0.0135498 ,\n",
              "        0.04541016, -0.04638672, -0.0177002 , -0.0625    ,  0.03442383,\n",
              "       -0.02416992,  0.03088379,  0.09570312,  0.07958984,  0.03930664,\n",
              "        0.0279541 , -0.0859375 ,  0.08105469,  0.06640625, -0.00041962,\n",
              "       -0.06933594,  0.03588867, -0.03417969,  0.04492188, -0.00772095,\n",
              "       -0.00741577, -0.04760742,  0.01397705, -0.09960938,  0.0246582 ,\n",
              "       -0.09960938,  0.11474609,  0.03173828,  0.02209473,  0.07226562,\n",
              "        0.03686523,  0.02563477,  0.01367188, -0.02734375,  0.00592041,\n",
              "       -0.06738281,  0.05053711, -0.02832031, -0.04516602, -0.01733398,\n",
              "        0.02111816,  0.03515625, -0.04296875,  0.06640625,  0.12207031,\n",
              "        0.12353516,  0.0039978 ,  0.04516602, -0.01855469,  0.04833984,\n",
              "        0.04516602,  0.08691406,  0.02941895,  0.03759766,  0.03442383,\n",
              "       -0.07373047, -0.0402832 , -0.14648438, -0.02441406, -0.01953125,\n",
              "        0.0065918 , -0.0018158 , -0.01092529,  0.09326172,  0.06542969,\n",
              "        0.01843262, -0.09326172, -0.01574707, -0.07128906, -0.08935547,\n",
              "       -0.07128906, -0.03015137, -0.01300049,  0.01635742, -0.01831055,\n",
              "        0.01483154,  0.00500488,  0.00366211,  0.04760742, -0.06884766],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(model.vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jHRR5P6WXiy",
        "outputId": "18340ee6-3f76-49d6-edf6-84c9c4ebe281"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3000000"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model['the'][:100].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAcIIa7KWoTx",
        "outputId": "888f7993-3664-49bc-9fa8-68847f9fed93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100,)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Now Convert genism dictionary to python dictionary in 200-D (Dimensional)"
      ],
      "metadata": {
        "id": "PfeH1zLZHbYZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding=dict()\n",
        "\n",
        "for k in model.vocab:\n",
        "  embedding[k]=model[k][:200]"
      ],
      "metadata": {
        "id": "Ni5P9VJYXnvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding['the']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuviUUHAYh0L",
        "outputId": "2be17ac0-8106-464e-d609-4dfc8e280df8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.08007812,  0.10498047,  0.04980469,  0.0534668 , -0.06738281,\n",
              "       -0.12060547,  0.03515625, -0.11865234,  0.04394531,  0.03015137,\n",
              "       -0.05688477, -0.07617188,  0.01287842,  0.04980469, -0.08496094,\n",
              "       -0.06347656,  0.00628662, -0.04321289,  0.02026367,  0.01330566,\n",
              "       -0.01953125,  0.09277344, -0.171875  , -0.00131989,  0.06542969,\n",
              "        0.05834961, -0.08251953,  0.0859375 , -0.00318909,  0.05859375,\n",
              "       -0.03491211, -0.0123291 , -0.0480957 , -0.00302124,  0.05639648,\n",
              "        0.01495361, -0.07226562, -0.05224609,  0.09667969,  0.04296875,\n",
              "       -0.03540039, -0.07324219,  0.03271484, -0.06176758,  0.00787354,\n",
              "        0.0035553 , -0.00878906,  0.0390625 ,  0.03833008,  0.04443359,\n",
              "        0.06982422,  0.01263428, -0.00445557, -0.03320312, -0.04272461,\n",
              "        0.09765625, -0.02160645, -0.0378418 ,  0.01190186, -0.01391602,\n",
              "       -0.11328125,  0.09326172, -0.03930664, -0.11621094,  0.02331543,\n",
              "       -0.01599121,  0.02636719,  0.10742188, -0.00466919,  0.09619141,\n",
              "        0.0279541 , -0.05395508,  0.08544922, -0.03686523, -0.02026367,\n",
              "       -0.08544922,  0.125     ,  0.14453125,  0.0267334 ,  0.15039062,\n",
              "        0.05273438, -0.18652344,  0.08154297, -0.01062012, -0.03735352,\n",
              "       -0.07324219, -0.07519531,  0.03613281, -0.13183594,  0.00616455,\n",
              "        0.05078125,  0.04516602,  0.0100708 , -0.15039062, -0.06005859,\n",
              "        0.05761719, -0.00692749,  0.01586914, -0.0213623 ,  0.10351562],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "fUnZJiEDZFke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating Embedding Matrix in 100-D (Dimensional)\n",
        "\n",
        "**Google Colab give us 12gb ram in free version so that why we are only load and use 100-Dimensional Embedding. if we have more then 12gb ram then we can use higher dimensions**"
      ],
      "metadata": {
        "id": "tazjAqcLHyRu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dims=100\n",
        "flag=1\n",
        "word_index = {w: i for i, w in enumerate(embedding, 1)}\n",
        "embedding_matrix = np.zeros((len(word_index)+1, dims))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embedding.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix[i] = embedding_vector[:dims]\n",
        "        "
      ],
      "metadata": {
        "id": "D9pRTGptYt7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2-HtXkSZMzb",
        "outputId": "8fb8053a-a441-4f81-aa16-4f78084a65eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.0703125 ,  0.08691406,  0.08789062,  0.0625    ,  0.06933594,\n",
              "       -0.10888672, -0.08154297, -0.15429688,  0.02075195,  0.13183594,\n",
              "       -0.11376953, -0.03735352,  0.06933594,  0.078125  , -0.10302734,\n",
              "       -0.09765625,  0.04418945,  0.10253906, -0.06079102, -0.03613281,\n",
              "       -0.04541016,  0.04736328, -0.12060547, -0.06396484,  0.0022583 ,\n",
              "        0.03710938, -0.00291443,  0.11767578,  0.06176758,  0.06396484,\n",
              "        0.08105469, -0.06884766, -0.0213623 ,  0.05517578, -0.08544922,\n",
              "        0.06884766, -0.12792969, -0.03320312,  0.09863281,  0.17578125,\n",
              "        0.11083984, -0.03466797, -0.04711914, -0.00848389,  0.03588867,\n",
              "        0.10302734,  0.02697754, -0.02868652, -0.00512695,  0.10644531,\n",
              "        0.05981445,  0.09423828,  0.03369141, -0.02709961, -0.09423828,\n",
              "        0.00102997, -0.04833984,  0.03442383,  0.08105469, -0.11328125,\n",
              "       -0.08886719,  0.03588867, -0.14550781, -0.24414062, -0.06152344,\n",
              "        0.05297852,  0.05688477,  0.1796875 ,  0.06103516,  0.08691406,\n",
              "        0.12402344, -0.0402832 ,  0.02258301,  0.17773438, -0.02966309,\n",
              "       -0.02966309,  0.1171875 ,  0.03112793, -0.09619141,  0.06640625,\n",
              "        0.00469971, -0.08007812,  0.06298828, -0.02062988, -0.0546875 ,\n",
              "       -0.13574219, -0.06347656,  0.08349609, -0.06396484,  0.02148438,\n",
              "        0.07714844, -0.03710938, -0.03369141, -0.18359375, -0.07275391,\n",
              "        0.01586914,  0.09326172, -0.06152344, -0.01422119, -0.00344849])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Store that Embedding Matrix into numpy format in google drive then restart your google colab gpu."
      ],
      "metadata": {
        "id": "ZCUtTvY4IBUB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('/content/drive/MyDrive/embedding_matrix.npy',embedding_matrix)"
      ],
      "metadata": {
        "id": "wEG3r3nykWju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load the numpy file (embedding_matrix.npy) with out loading word2vec"
      ],
      "metadata": {
        "id": "RnPk_RgVIv7Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "embedding_matrix=np.load('/content/drive/MyDrive/embedding_matrix.npy')"
      ],
      "metadata": {
        "id": "ZPp8Aj9Fk1xW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using this embedding matrix any where in your problem like (Machine Translation,Seniment Analysis and NER etc.)"
      ],
      "metadata": {
        "id": "1vyVZMmLJEEL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import string\n",
        "import re\n",
        "from unicodedata import normalize\n",
        "import numpy as np\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.models import Sequential,load_model\n",
        "from keras.layers import LSTM,Dense,Embedding,RepeatVector,TimeDistributed,Bidirectional,GRU\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "import pandas as pd\n",
        "from string import punctuation\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Markdown, display\n",
        "from keras.layers import Dropout\n",
        "\n",
        "\n",
        "def printmd(string):\n",
        "    # Print with Markdowns    \n",
        "    display(Markdown(string))"
      ],
      "metadata": {
        "id": "q3mFavSYmlH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How many sentences will be used\n",
        "# Limit the sentences to 10.000 on Kaggle to avoid exceding the\n",
        "# available RAM space\n",
        "# Build a generator to avoid this issue\n",
        "\n",
        "total_sentences = 85221\n",
        "\n",
        "# Load the dataset\n",
        "dataset = pd.read_excel(\"/content/drive/MyDrive/data.xlsx\", nrows = total_sentences)\n",
        "\n",
        "\n",
        "# What proportion of the sentences will be used for the test set\n",
        "test_proportion = 0.3\n",
        "train_test_threshold = int( (1-test_proportion) * total_sentences)\n",
        "\n",
        "printmd(f'## {total_sentences} \"parallel sentences\" will be loaded (original sentence + its translation)')\n",
        "printmd(f'## {train_test_threshold} \"parallel sentences\" will be used to train the model')\n",
        "printmd(f'## {total_sentences-train_test_threshold} \"parallel sentences\" will be used to test the model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "id": "QCIVDEp_mlV_",
        "outputId": "b59951fb-f795-49c0-a057-63e48dc5b4f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## 85221 \"parallel sentences\" will be loaded (original sentence + its translation)"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## 59654 \"parallel sentences\" will be used to train the model"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## 25567 \"parallel sentences\" will be used to test the model"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle the dataset\n",
        "dataset = dataset.sample(frac=1, random_state=0)\n",
        "dataset.iloc[1000:1010]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "eR2jRF5ImlYx",
        "outputId": "1b8c1a27-a4ee-48ca-f111-37a3f5694671"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               English  \\\n",
              "42870         The chief was deciding to be a good man.   \n",
              "3261                    I have an orange and an apple.   \n",
              "73922                   I had hoped to meet her there.   \n",
              "84184                  I know that Shazim is agnostic.   \n",
              "79760  He is a director and should be treated as such.   \n",
              "61886                I can not believe Anees said yes.   \n",
              "65728                 Waasif did not follow the rules.   \n",
              "36340                    It sounds very strange to me.   \n",
              "4064                          Balam took off his belt.   \n",
              "24879                  We have just got to keep going.   \n",
              "\n",
              "                                               PSL  \n",
              "42870  Was The chief be a good man decides to now.  \n",
              "3261                    I an orange an apple have.  \n",
              "73922              was I there her meet hope full.  \n",
              "84184                 I know that Shazim agnostic.  \n",
              "79760                      He director such treat.  \n",
              "61886                 I believe not was Anees say.  \n",
              "65728                 was Waasif rules follow not.  \n",
              "36340                   It me very strange sounds.  \n",
              "4064                  was Balam his belt take off.  \n",
              "24879                    We just go keep get full.  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ca390467-3250-4a7c-9bae-362c3c2778dc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>PSL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>42870</th>\n",
              "      <td>The chief was deciding to be a good man.</td>\n",
              "      <td>Was The chief be a good man decides to now.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3261</th>\n",
              "      <td>I have an orange and an apple.</td>\n",
              "      <td>I an orange an apple have.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73922</th>\n",
              "      <td>I had hoped to meet her there.</td>\n",
              "      <td>was I there her meet hope full.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84184</th>\n",
              "      <td>I know that Shazim is agnostic.</td>\n",
              "      <td>I know that Shazim agnostic.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79760</th>\n",
              "      <td>He is a director and should be treated as such.</td>\n",
              "      <td>He director such treat.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61886</th>\n",
              "      <td>I can not believe Anees said yes.</td>\n",
              "      <td>I believe not was Anees say.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65728</th>\n",
              "      <td>Waasif did not follow the rules.</td>\n",
              "      <td>was Waasif rules follow not.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36340</th>\n",
              "      <td>It sounds very strange to me.</td>\n",
              "      <td>It me very strange sounds.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4064</th>\n",
              "      <td>Balam took off his belt.</td>\n",
              "      <td>was Balam his belt take off.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24879</th>\n",
              "      <td>We have just got to keep going.</td>\n",
              "      <td>We just go keep get full.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ca390467-3250-4a7c-9bae-362c3c2778dc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ca390467-3250-4a7c-9bae-362c3c2778dc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ca390467-3250-4a7c-9bae-362c3c2778dc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean(string):\n",
        "    # Clean the string\n",
        "    string = string.replace(\"\\u202f\",\" \") # Replace no-break space with space\n",
        "    string = string.lower()\n",
        "    \n",
        "    # Delete the punctuation and the numbers\n",
        "    for p in punctuation + \"«»\" + \"0123456789\":\n",
        "        string = string.replace(p,\" \")\n",
        "        \n",
        "        \n",
        "    string = re.sub('\\s+',' ', string)\n",
        "    string = string.strip()\n",
        "           \n",
        "    return string\n",
        "\n",
        "# Clean the sentences\n",
        "dataset[\"English\"] = dataset[\"English\"].apply(lambda x: clean(x))\n",
        "dataset[\"PSL\"] = dataset[\"PSL\"].apply(lambda x: clean(x))\n",
        "\n",
        "# Select one part of the dataset\n",
        "dataset = dataset.values\n",
        "dataset = dataset[:total_sentences]\n",
        "\n",
        "# split into train/test\n",
        "train, test = dataset[:train_test_threshold], dataset[train_test_threshold:]\n",
        "\n",
        "# Define the name of the source and of the target\n",
        "# This will be used in the outputs of this notebook\n",
        "source_str, target_str = \"PSL\", \"English\"\n",
        "\n",
        "# The index in the numpy array of the source and of the target\n",
        "idx_src, idx_tar = 1,0"
      ],
      "metadata": {
        "id": "Z6stdJgKmlbq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_tokenizer(lines):\n",
        "    # fit a tokenizer\n",
        "    tokenizer = Tokenizer()\n",
        "    tokenizer.fit_on_texts(lines)\n",
        "    return tokenizer\n",
        " \n",
        "def max_len(lines):\n",
        "    # max sentence length\n",
        "    return max(len(line.split()) for line in lines)\n",
        "\n",
        "def encode_sequences(tokenizer, length, lines):\n",
        "    # encode and pad sequences\n",
        "    X = tokenizer.texts_to_sequences(lines) # integer encode sequences\n",
        "    X = pad_sequences(X, maxlen=length, padding='post') # pad sequences with 0 values\n",
        "    return X\n",
        " \n",
        "def encode_output(sequences, vocab_size):\n",
        "    # one hot encode target sequence\n",
        "    ylist = list()\n",
        "    for sequence in sequences:\n",
        "        encoded = to_categorical(sequence, num_classes=vocab_size)\n",
        "        ylist.append(encoded)\n",
        "    y = np.array(ylist)\n",
        "    y = y.reshape(sequences.shape[0], sequences.shape[1], vocab_size)\n",
        "    return y\n",
        " \n",
        "# Prepare target tokenizer\n",
        "tar_tokenizer = create_tokenizer(dataset[:, idx_tar])\n",
        "tar_vocab_size = len(tar_tokenizer.word_index) + 1\n",
        "tar_length = max_len(dataset[:, idx_tar])\n",
        "printmd(f'\\nTarget ({target_str}) Vocabulary Size: {tar_vocab_size}')\n",
        "printmd(f'Target ({target_str}) Max Length: {tar_length}')\n",
        "\n",
        "# Prepare source tokenizer\n",
        "src_tokenizer = create_tokenizer(dataset[:, idx_src])\n",
        "src_vocab_size = len(src_tokenizer.word_index) + 1\n",
        "src_length = max_len(dataset[:, idx_src])\n",
        "printmd(f'\\nSource ({source_str}) Vocabulary Size: {src_vocab_size}')\n",
        "printmd(f'Source ({source_str}) Max Length: {src_length}\\n')\n",
        " \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        },
        "id": "YzwvfV-9mlep",
        "outputId": "c825df64-bf9d-4a9c-b86b-fc8ae58eb915"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\nTarget (English) Vocabulary Size: 9256"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Target (English) Max Length: 12"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\nSource (PSL) Vocabulary Size: 8089"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Source (PSL) Max Length: 14\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare training data\n",
        "trainX = encode_sequences(src_tokenizer, src_length, train[56000:59654, idx_src])\n",
        "trainY = encode_sequences(tar_tokenizer, tar_length, train[56000:59654, idx_tar])\n",
        "trainY = encode_output(trainY, tar_vocab_size)"
      ],
      "metadata": {
        "id": "faIoicQemliQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(src_vocab, tar_vocab, src_timesteps, tar_timesteps, n_units):\n",
        "    # Create the model\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(embedding_matrix.shape[0],embedding_matrix.shape[1],weights=[embedding_matrix],input_length=src_timesteps,trainable=False))\n",
        "    model.add(Bidirectional(LSTM(n_units)))\n",
        "    model.add(RepeatVector(tar_timesteps))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Bidirectional(LSTM(n_units, return_sequences=True)))\n",
        "\n",
        "    model.add(TimeDistributed(Dense(tar_vocab, activation='sigmoid')))\n",
        "    return model\n",
        " "
      ],
      "metadata": {
        "id": "ax_mzhEImaep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create model\n",
        "model = create_model(src_vocab_size, tar_vocab_size, src_length, tar_length, 256)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy')"
      ],
      "metadata": {
        "id": "FzZalMFPmkbp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdscRoWunerX",
        "outputId": "585cbc0a-5097-4dd9-dfee-671b57ebee15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 14, 100)           300000100 \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 512)              731136    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " repeat_vector (RepeatVector  (None, 12, 512)          0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 12, 512)           0         \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 12, 512)          1574912   \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " time_distributed (TimeDistr  (None, 12, 9256)         4748328   \n",
            " ibuted)                                                         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 307,054,476\n",
            "Trainable params: 7,054,376\n",
            "Non-trainable params: 300,000,100\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(trainX, \n",
        "          trainY, \n",
        "          epochs=100, \n",
        "          batch_size=128, \n",
        "          validation_split=0.1, \n",
        "          verbose=1,\n",
        "          callbacks=[\n",
        "                        EarlyStopping(\n",
        "                        monitor='val_loss',\n",
        "                        patience=10,\n",
        "                        restore_best_weights=True\n",
        "                    )\n",
        "            ])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WS2tDTddmajE",
        "outputId": "d86ca510-2564-4262-e144-c3263b711261"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "26/26 [==============================] - 15s 282ms/step - loss: 1.4599 - val_loss: 1.4206\n",
            "Epoch 2/100\n",
            "26/26 [==============================] - 3s 123ms/step - loss: 1.3045 - val_loss: 1.4177\n",
            "Epoch 3/100\n",
            "26/26 [==============================] - 3s 121ms/step - loss: 1.1963 - val_loss: 1.3987\n",
            "Epoch 4/100\n",
            "26/26 [==============================] - 3s 104ms/step - loss: 1.1161 - val_loss: 1.4029\n",
            "Epoch 5/100\n",
            "26/26 [==============================] - 3s 103ms/step - loss: 1.0483 - val_loss: 1.4139\n",
            "Epoch 6/100\n",
            "26/26 [==============================] - 3s 106ms/step - loss: 0.9896 - val_loss: 1.4083\n",
            "Epoch 7/100\n",
            "26/26 [==============================] - 3s 104ms/step - loss: 0.9403 - val_loss: 1.4208\n",
            "Epoch 8/100\n",
            "26/26 [==============================] - 3s 106ms/step - loss: 0.8951 - val_loss: 1.4226\n",
            "Epoch 9/100\n",
            "26/26 [==============================] - 3s 103ms/step - loss: 0.8536 - val_loss: 1.4381\n",
            "Epoch 10/100\n",
            "26/26 [==============================] - 3s 103ms/step - loss: 0.8162 - val_loss: 1.4555\n",
            "Epoch 11/100\n",
            "26/26 [==============================] - 3s 112ms/step - loss: 0.7861 - val_loss: 1.4462\n",
            "Epoch 12/100\n",
            "26/26 [==============================] - 3s 104ms/step - loss: 0.7592 - val_loss: 1.4615\n",
            "Epoch 13/100\n",
            "26/26 [==============================] - 3s 112ms/step - loss: 0.7334 - val_loss: 1.4624\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/PSL_to_ENG_WORD2VEC.h5')"
      ],
      "metadata": {
        "id": "-1cijnqSmalO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "model = keras.models.load_model('/content/drive/MyDrive/PSL_to_ENG_WORD2VEC.h5')"
      ],
      "metadata": {
        "id": "6-vVjCsimaoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare test data\n",
        "testX = encode_sequences(src_tokenizer, src_length, test[:10000, idx_src])\n",
        "testY = encode_sequences(tar_tokenizer, tar_length, test[:10000, idx_tar])\n",
        "testY = encode_output(testY, tar_vocab_size)"
      ],
      "metadata": {
        "id": "UYhoYtg6mar3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def word_for_id(integer, tokenizer):\n",
        "    # map an integer to a word\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "        if index == integer:\n",
        "            return word\n",
        "    return None\n",
        " \n",
        "def predict_seq(model, tokenizer, source):\n",
        "    # generate target from a source sequence\n",
        "    prediction = model.predict(source, verbose=0)[0]\n",
        "    integers = [np.argmax(vector) for vector in prediction]\n",
        "    target = list()\n",
        "    \n",
        "    for i in integers:\n",
        "        word = word_for_id(i, tokenizer)\n",
        "        if word is None:\n",
        "            break\n",
        "        target.append(word)\n",
        "    return ' '.join(target)\n",
        "\n",
        "def compare_prediction(model, tokenizer, sources, raw_dataset, limit=20):\n",
        "    # evaluate a model\n",
        "    actual, predicted = [], []\n",
        "    src = f'{source_str.upper()} (SOURCE)'\n",
        "    tgt = f'{target_str.upper()} (TARGET)'\n",
        "    pred = f'AUTOMATIC TRANSLATION IN {target_str.upper()}'\n",
        "    print(f'{src:30} {tgt:25} {pred}\\n')\n",
        "    \n",
        "    for i, source in enumerate(sources): # translate encoded source text\n",
        "        source = source.reshape((1, source.shape[0]))\n",
        "        translation = predict_seq(model, tar_tokenizer, source)\n",
        "        raw_target, raw_src = raw_dataset[i]\n",
        "        print(f'{raw_src:30} {raw_target:25} {translation}')\n",
        "        if i >= limit: # Display some of the result\n",
        "            break\n",
        " \n",
        "# test on some training sequences\n",
        "# print('### Result on the Training Set ###')\n",
        "# compare_prediction(model, tar_tokenizer, trainX, train)\n",
        "\n",
        "# test on some test sequences\n",
        "print('\\n\\n### Result on the Test Set ###')\n",
        "compare_prediction(model, tar_tokenizer, testX,test[:10000,:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rS0Imw_41QDD",
        "outputId": "ce642d79-a06e-4261-f4d4-38e61c2e9601"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "### Result on the Test Set ###\n",
            "PSL (SOURCE)                   ENGLISH (TARGET)          AUTOMATIC TRANSLATION IN ENGLISH\n",
            "\n",
            "was she food cook full         she had cooked food       she had cooked food\n",
            "was i them tell not            i did not tell them       i did not tell them\n",
            "i stupid feel                  i feel stupid             i feel well\n",
            "ranjhoo it like after          ranjhoo will like it      ranjhoo will will it\n",
            "was they their parents obey not they did not obey their parents they did not kiss their\n",
            "hello                          hello                     hello\n",
            "i brothers sisters have        i have eight brothers and sisters i have missed lunch\n",
            "i now go go now                i am going to go now      i am going to to to\n",
            "i join in yes no               can i join in             can i join in\n",
            "was it important               it was important          it was a\n",
            "you mail full                  you have mail             you have lost\n",
            "everybody know i you hate      everybody knows i hate you everybody knows you you call\n",
            "was i you totally              i was totally into you    i missed you\n",
            "was you part get               you got the part          you got some get\n",
            "was i it properly handle       i handled it properly     i was it the\n",
            "was javaid say that was bakhtawar lucky not javaid said that bakhtawar was not lucky fazal said that he was not finished\n",
            "was waasif lamp turn off       waasif turned off the lamp waasif turned the the the\n",
            "we them trust yes no           can we trust them         can we trust\n",
            "was my mother them sew full now not my mother had not been sewing them my mother had not been to them\n",
            "was kitten milk drink full now the kitten had been drinking milk the kitten had been drinking milk\n",
            "was husnain champagne drink want husnain wanted to drink champagne ashraf wanted to to the cream\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def bleu_score(model, tokenizer, sources, raw_dataset):\n",
        "    # Get the bleu score of a model\n",
        "    actual, predicted = [], []\n",
        "    for i, source in enumerate(sources):\n",
        "        # translate encoded source text\n",
        "        source = source.reshape((1, source.shape[0]))\n",
        "        translation = predict_seq(model, tar_tokenizer, source)\n",
        "        raw_target, raw_src = raw_dataset[i]\n",
        "        actual.append([raw_target.split()])\n",
        "        predicted.append(translation.split())\n",
        "        \n",
        "    bleu_dic = {}\n",
        "    bleu_dic['1-grams'] = corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0))\n",
        "    bleu_dic['1-2-grams'] = corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0))\n",
        "    bleu_dic['1-3-grams'] = corpus_bleu(actual, predicted, weights=(0.3, 0.3, 0.3, 0))\n",
        "    bleu_dic['1-4-grams'] = corpus_bleu(actual, predicted, weights=(0.25, 0.25, 0.25, 0.25))\n",
        "    \n",
        "    return bleu_dic\n",
        "\n",
        "# Compute the BLEU Score\n",
        "# bleu_train = bleu_score(model, tar_tokenizer, trainX, train)\n",
        "bleu_test = bleu_score(model, tar_tokenizer, testX, test[:10000,:])"
      ],
      "metadata": {
        "id": "0qdnuvgY1QFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.bar(x = bleu_test.keys(), height = bleu_test.values())\n",
        "plt.title(\"BLEU Score with the first 10000 test set\")\n",
        "plt.ylim((0,1))\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "KW0g3r_r1QI_",
        "outputId": "8c880e66-3973-41eb-d2c7-253e44d0114b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(bleu_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGM7kGpC1QMW",
        "outputId": "2574588e-4650-4f39-a07d-80f8d14469a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'1-grams': 0.5531132200807165, '1-2-grams': 0.4280897648243376, '1-3-grams': 0.37261061449948585, '1-4-grams': 0.26261905350590725}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install jiwer\n",
        "def word_for_id(integer, tokenizer):\n",
        "    # map an integer to a word\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "        if index == integer:\n",
        "            return word\n",
        "    return None\n",
        " \n",
        "def predict_seq(model, tokenizer, source):\n",
        "    # generate target from a source sequence\n",
        "    prediction = model.predict(source, verbose=0)[0]\n",
        "    integers = [np.argmax(vector) for vector in prediction]\n",
        "    target = list()\n",
        "    \n",
        "    for i in integers:\n",
        "        word = word_for_id(i, tokenizer)\n",
        "        if word is None:\n",
        "            break\n",
        "        target.append(word)\n",
        "    return ' '.join(target)\n",
        "\n",
        "def compare_prediction(model, tokenizer, sources, raw_dataset, limit=20):\n",
        "    # evaluate a model\n",
        "    actual, predicted = [], []\n",
        "    src = f'{source_str.upper()} (SOURCE)'\n",
        "    tgt = f'{target_str.upper()} (TARGET)'\n",
        "    pred = f'AUTOMATIC TRANSLATION IN {target_str.upper()}'\n",
        "    #print(f'{src:30} {tgt:25} {pred}\\n')\n",
        "    \n",
        "    for i, source in enumerate(sources): # translate encoded source text\n",
        "        source = source.reshape((1, source.shape[0]))\n",
        "        translation = predict_seq(model, tar_tokenizer, source)\n",
        "        raw_target, raw_src = raw_dataset[i]\n",
        "        #print(f'{raw_src:30} {raw_target:25} {translation}')\n",
        "        #print(translation)     #predicit\n",
        "        #print(raw_target)      #actual\n",
        "        actual.append(raw_target)\n",
        "        predicted.append(translation)\n",
        "        if i >= limit: # Display some of the result\n",
        "            return actual,predicted\n",
        "            break\n",
        " \n",
        "# # test on some training sequences!pip install jiwer\n",
        "# print('### Result on the Training Set ###')\n",
        "# compare_prediction(model, tar_tokenizer, trainX, train)\n",
        "\n",
        "# test on some test sequences\n",
        "print('\\n\\n### Result on the Test Set ###')\n",
        "Actual,Predicted=compare_prediction(model, tar_tokenizer, testX,test[:10000,:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbLKObD51QQE",
        "outputId": "56540210-99a0-4f1a-e666-de0cb848f2bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jiwer\n",
            "  Downloading jiwer-2.3.0-py3-none-any.whl (15 kB)\n",
            "Collecting python-Levenshtein==0.12.2\n",
            "  Downloading python-Levenshtein-0.12.2.tar.gz (50 kB)\n",
            "\u001b[?25l\r\u001b[K     |██████▌                         | 10 kB 22.4 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 20 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 30 kB 2.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 40 kB 3.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 50 kB 2.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from python-Levenshtein==0.12.2->jiwer) (57.4.0)\n",
            "Building wheels for collected packages: python-Levenshtein\n",
            "  Building wheel for python-Levenshtein (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-Levenshtein: filename=python_Levenshtein-0.12.2-cp37-cp37m-linux_x86_64.whl size=149866 sha256=26ee384c0ea5de4e23738258cbd1ecd36ec0d1e01ea0bff5bf988d23e1b0bb26\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/5f/ca/7c4367734892581bb5ff896f15027a932c551080b2abd3e00d\n",
            "Successfully built python-Levenshtein\n",
            "Installing collected packages: python-Levenshtein, jiwer\n",
            "Successfully installed jiwer-2.3.0 python-Levenshtein-0.12.2\n",
            "\n",
            "\n",
            "### Result on the Test Set ###\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from jiwer import wer\n",
        "error=wer(Actual,Predicted)\n",
        "error"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhKyD76h1fYT",
        "outputId": "8256bfc7-a9d2-4839-b996-62be739f7c8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3402061855670103"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyter3\n",
        "import pyter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3stYDUw1fcX",
        "outputId": "9f5d66c1-e01b-4b69-d04d-2ce1e9114a56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyter3\n",
            "  Downloading pyter3-0.3-py3-none-any.whl (4.1 kB)\n",
            "Installing collected packages: pyter3\n",
            "Successfully installed pyter3-0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i=0\n",
        "sum=0\n",
        "while i<len(Actual):\n",
        "  #print(pyter.ter(Actual[i].split(),Predicted[i].split()))\n",
        "  sum+=pyter.ter(Actual[i].split(),Predicted[i].split())\n",
        "  i=i+1\n",
        "\n",
        "\n",
        "\n",
        "sum=sum/len(Actual)\n",
        "sum"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LorZ4n6W1feW",
        "outputId": "6d157661-26c7-4395-d4df-05f7b6702bbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3597505668934241"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "8Nzqugwd1fhM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}